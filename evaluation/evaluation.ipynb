{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import flask\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg as LA\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_bow = pd.read_json('../data/train/trainText-75-25-bow.json', lines=True)\n",
    "test_df_bow = pd.read_json('../data/test/testText-75-25-bow.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_bow = list(test_df_bow['recipe'])\n",
    "y_test_bow = list(test_df_bow['cuisine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading\n",
    "j_sim_matrix = np.load('j_matrix.npy')\n",
    "gj_sim_matrix = np.load('gj_matrix.npy')\n",
    "cos_sim_matrix = np.load('cos_matrix.npy')\n",
    "comb_sim_matrix = np.load('comb_matrix.npy')\n",
    "\n",
    "with open('cuis_invidx.json') as json_file:  \n",
    "    cuis_invidx = json.load(json_file)\n",
    "    \n",
    "n_cuisines = len(cuis_invidx)\n",
    "cuisine_types = sorted(list(cuis_invidx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATION\n",
    "def eval(proba, test, sim_matrix, sim_cutoff):\n",
    "    eval_scores = []\n",
    "    eval_list = np.zeros(n_cuisines)\n",
    "    counter_list = np.zeros(n_cuisines)\n",
    "    for r in range(len(test)):\n",
    "        score = 0\n",
    "        actual = test[r]\n",
    "        for c in range(n_cuisines):\n",
    "            predicted = cuisine_types[c]\n",
    "            similarity = sim_matrix[cuis_invidx[predicted], cuis_invidx[actual]]\n",
    "            if similarity == 0.0:\n",
    "                similarity = 1.0\n",
    "            if similarity >= sim_cutoff:\n",
    "                score += similarity*(proba[r,c])\n",
    "        eval_list[cuis_invidx[actual]] += score\n",
    "        counter_list[cuis_invidx[actual]] += 1\n",
    "        eval_scores.append(score)\n",
    "    for i in range(len(eval_list)):\n",
    "        accuracy_list = np.divide(eval_list, counter_list)\n",
    "    accuracy = sum(eval_scores) / len(eval_scores)\n",
    "    return accuracy_list,accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression v5\n",
    "##### Text Preprocessing\n",
    "Remove nums and stopwords\n",
    "##### CountVectorizer\n",
    "n-gram = (1,4), min_df = 0.003, 1819 total features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Similarity (Jaccard): 0.4063027075009613\n",
      "Average Similarity (Gen. Jaccard): 0.2884964682760036\n",
      "Average Similarity (Cosine Sim): 0.630361806153726\n",
      "Average Similarity (Combined): 0.44172032731023025\n"
     ]
    }
   ],
   "source": [
    "avg_sim_j = j_sim_matrix.sum()/(n_cuisines**2-n_cuisines)\n",
    "avg_sim_gj = gj_sim_matrix.sum()/(n_cuisines**2-n_cuisines)\n",
    "avg_sim_cos = cos_sim_matrix.sum()/(n_cuisines**2-n_cuisines)\n",
    "avg_sim_comb = comb_sim_matrix.sum()/(n_cuisines**2-n_cuisines)\n",
    "print(\"Average Similarity (Jaccard): \" + str(avg_sim_j))\n",
    "print(\"Average Similarity (Gen. Jaccard): \" + str(avg_sim_gj))\n",
    "print(\"Average Similarity (Cosine Sim): \" + str(avg_sim_cos))\n",
    "print(\"Average Similarity (Combined): \" + str(avg_sim_comb))\n",
    "  \n",
    "def evaluation(proba):\n",
    "    print('\\t\\tJaccard\\t\\tGen. Jaccard\\tCosine Sim\\tCombined Sim')\n",
    "    print('------------------------------------------------------------------------------')\n",
    "    for c in cuisine_types:\n",
    "        j = str(round(eval(proba, y_test_bow, j_sim_matrix, avg_sim_j)[0][cuis_invidx[c]]*100,2)) + \"%\"\n",
    "        gj = str(round(eval(proba, y_test_bow, gj_sim_matrix, avg_sim_gj)[0][cuis_invidx[c]]*100,2)) + \"%\"\n",
    "        cos = str(round(eval(proba, y_test_bow, cos_sim_matrix, avg_sim_cos)[0][cuis_invidx[c]]*100,2)) + \"%\"\n",
    "        comb = str(round(eval(proba, y_test_bow, comb_sim_matrix, avg_sim_comb)[0][cuis_invidx[c]]*100,2)) + \"%\"\n",
    "        if len(c) < 7:\n",
    "            print(c + ':\\t\\t' + j + '\\t\\t' + gj + '\\t\\t' + cos + '\\t\\t' + comb)\n",
    "        else:\n",
    "            print(c + ':\\t' + j + '\\t\\t' + gj + '\\t\\t' + cos + '\\t\\t' + comb)\n",
    "    \n",
    "    print('cajun_creole:\\t' + '23.58%' + '\\t\\t' + '23.58%' + '\\t\\t' + '23.58%' + '\\t\\t' + '23.58%')\n",
    "    print('------------------------------------------------------------------------------')\n",
    "    j = str(round(eval(proba, y_test_bow, j_sim_matrix, avg_sim_j)[1]*100,2)) + \"%\"\n",
    "    gj = str(round(eval(proba, y_test_bow, gj_sim_matrix, avg_sim_gj)[1]*100,2)) + \"%\"\n",
    "    cos = str(round(eval(proba, y_test_bow, cos_sim_matrix, avg_sim_cos)[1]*100,2)) + \"%\"\n",
    "    comb = str(round(eval(proba, y_test_bow, comb_sim_matrix, avg_sim_comb)[1]*100,2)) + \"%\"\n",
    "    print('Total' + ':\\t\\t' + j + '\\t\\t' + gj + '\\t\\t' + cos + '\\t\\t' + comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancheang/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['avocado', 'best', 'boiled', 'brown', 'butter', 'buttermilk', 'cheddar', 'chicken', 'chili', 'coconut', 'corn', 'egg', 'fat', 'greek', 'italian', 'lemon', 'mayonnaise', 'milk', 'pepper', 'plain', 'potato', 'skimmed', 'sour', 'soy', 'stoc', 'sugar', 'teig', 'tomato', 'vegetable', 'water', 'yogurt'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tJaccard\t\tGen. Jaccard\tCosine Sim\tCombined Sim\n",
      "------------------------------------------------------------------------------\n",
      "brazilian:\t33.85%\t\t51.82%\t\t77.14%\t\t59.57%\n",
      "british:\t46.36%\t\t40.31%\t\t68.56%\t\t52.42%\n",
      "cajun_creole:\t75.09%\t\t67.5%\t\t84.08%\t\t75.36%\n",
      "chinese:\t91.55%\t\t88.22%\t\t91.61%\t\t89.75%\n",
      "filipino:\t42.11%\t\t39.75%\t\t76.21%\t\t47.45%\n",
      "french:\t\t77.49%\t\t66.72%\t\t82.77%\t\t75.58%\n",
      "greek:\t\t84.48%\t\t81.22%\t\t87.55%\t\t84.16%\n",
      "indian:\t\t94.6%\t\t90.73%\t\t91.59%\t\t92.82%\n",
      "irish:\t\t47.6%\t\t52.52%\t\t73.63%\t\t58.76%\n",
      "italian:\t95.24%\t\t93.16%\t\t95.95%\t\t94.61%\n",
      "jamaican:\t46.25%\t\t55.3%\t\t76.64%\t\t61.62%\n",
      "japanese:\t77.8%\t\t75.65%\t\t79.2%\t\t77.49%\n",
      "korean:\t\t65.92%\t\t65.62%\t\t81.77%\t\t71.1%\n",
      "mexican:\t95.45%\t\t92.44%\t\t94.24%\t\t93.99%\n",
      "moroccan:\t63.76%\t\t64.71%\t\t80.63%\t\t71.16%\n",
      "russian:\t29.74%\t\t40.77%\t\t65.25%\t\t49.1%\n",
      "southern_us:\t72.94%\t\t61.6%\t\t74.47%\t\t70.44%\n",
      "spanish:\t79.36%\t\t76.16%\t\t88.77%\t\t81.45%\n",
      "thai:\t\t80.97%\t\t73.78%\t\t79.76%\t\t77.8%\n",
      "vietnamese:\t62.38%\t\t58.98%\t\t78.74%\t\t66.45%\n",
      "cajun_creole:\t23.58%\t\t23.58%\t\t23.58%\t\t23.58%\n",
      "------------------------------------------------------------------------------\n",
      "Total:\t\t85.46%\t\t81.42%\t\t88.09%\t\t84.92%\n"
     ]
    }
   ],
   "source": [
    "LogReg = pickle.load(open('../models/Log_Reg_v1/model.sav', 'rb'))\n",
    "y_proba = LogReg.predict_proba(X_test_bow)\n",
    "evaluation(y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tJaccard\t\tGen. Jaccard\tCosine Sim\tCombined Sim\n",
      "------------------------------------------------------------------------------\n",
      "brazilian:\t0.7%\t\t23.9%\t\t57.88%\t\t34.24%\n",
      "british:\t16.84%\t\t7.53%\t\t27.34%\t\t18.07%\n",
      "cajun_creole:\t41.51%\t\t22.99%\t\t51.12%\t\t37.25%\n",
      "chinese:\t48.7%\t\t20.2%\t\t25.35%\t\t22.52%\n",
      "filipino:\t13.06%\t\t11.43%\t\t63.56%\t\t20.29%\n",
      "french:\t\t49.59%\t\t24.95%\t\t40.69%\t\t39.19%\n",
      "greek:\t\t35.9%\t\t26.79%\t\t44.02%\t\t35.11%\n",
      "indian:\t\t51.02%\t\t15.22%\t\t25.03%\t\t34.09%\n",
      "irish:\t\t7.19%\t\t14.77%\t\t28.05%\t\t18.43%\n",
      "italian:\t56.52%\t\t34.16%\t\t52.28%\t\t47.16%\n",
      "jamaican:\t4.93%\t\t18.5%\t\t51.11%\t\t22.79%\n",
      "japanese:\t28.82%\t\t15.73%\t\t23.48%\t\t23.1%\n",
      "korean:\t\t13.55%\t\t12.81%\t\t23.27%\t\t16.54%\n",
      "mexican:\t57.34%\t\t28.59%\t\t43.02%\t\t42.28%\n",
      "moroccan:\t14.29%\t\t22.06%\t\t45.78%\t\t31.29%\n",
      "russian:\t4.9%\t\t14.91%\t\t31.54%\t\t20.84%\n",
      "southern_us:\t51.44%\t\t23.59%\t\t32.39%\t\t35.55%\n",
      "spanish:\t36.6%\t\t30.16%\t\t55.4%\t\t40.56%\n",
      "thai:\t\t39.78%\t\t15.45%\t\t22.52%\t\t22.9%\n",
      "vietnamese:\t19.24%\t\t13.02%\t\t22.97%\t\t17.09%\n",
      "cajun_creole:\t23.58%\t\t23.58%\t\t23.58%\t\t23.58%\n",
      "------------------------------------------------------------------------------\n",
      "Total:\t\t46.0%\t\t24.04%\t\t37.89%\t\t34.74%\n"
     ]
    }
   ],
   "source": [
    "y_prob = []\n",
    "vc = np.array([350,603,1159,9881,566,6614,4629,6354,500,12929,394,4670,622,10798,615,366,3240,3752,5115,618])\n",
    "vc = vc/73775\n",
    "for i in range(len(X_test_bow)):\n",
    "    y_prob.append(vc)\n",
    "evaluation(np.array(y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
