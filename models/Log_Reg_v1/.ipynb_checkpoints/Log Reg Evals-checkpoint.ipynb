{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "train_df = pd.read_json('../../data/train/new-train.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_json('../../data/test/new-test.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>romaine lettuce, black olives, grape tomatoes,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>greek</td>\n",
       "      <td>ground pork, finely chopped fresh parsley, oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>greek</td>\n",
       "      <td>minced garlic, dried oregano, red wine vinegar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>greek</td>\n",
       "      <td>orange, anise, cinnamon sticks, unflavored gel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>greek</td>\n",
       "      <td>fresh dill, yoghurt, salt, myzithra, large egg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cuisine                                        ingredients  label\n",
       "0   greek  romaine lettuce, black olives, grape tomatoes,...      0\n",
       "1   greek  ground pork, finely chopped fresh parsley, oni...      0\n",
       "2   greek  minced garlic, dried oregano, red wine vinegar...      0\n",
       "3   greek  orange, anise, cinnamon sticks, unflavored gel...      0\n",
       "4   greek  fresh dill, yoghurt, salt, myzithra, large egg...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "  \n",
    "def lemmatize(text):\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in text.split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['ingredients'] = train_df['ingredients'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['ingredients'] = test_df['ingredients'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = list(train_df['ingredients'])\n",
    "labels = list(train_df['cuisine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = list(test_df['ingredients'])\n",
    "y_test = list(test_df['cuisine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "corpus = pickle.load(open( '../../data/recipes.data', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "file = open(\"stopwords.txt\", \"r\")\n",
    "sw = file.read().lower().split('\\n')\n",
    "sw = sw + stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features: 7000\n",
      "Training Accuracy: 0.784927\n",
      "Testing Accuracy: 0.743893\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(2,2), max_features = 7000, binary=True, stop_words=sw)\n",
    "vectorizer.fit(corpus)\n",
    "X_train = vectorizer.transform(recipes).toarray()\n",
    "y_train = labels\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "model = Pipeline([('vectorizer', vectorizer),('LR', clf)])\n",
    "y_pred = model.predict(X_test)\n",
    "print('Number of Features: %d'%len(vectorizer.get_feature_names()))\n",
    "print('Training Accuracy: %f'%metrics.accuracy_score(y_train, model.predict(recipes)))\n",
    "print('Testing Accuracy: %f'%metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2), max_features = 7000, binary=True, stop_words=sw)\n",
    "vectorizer.fit(corpus)\n",
    "X_train = vectorizer.transform(recipes).toarray()\n",
    "y_train = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features: 7000\n",
      "Training Accuracy: 0.870390\n",
      "Testing Accuracy: 0.832947\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "model = Pipeline([('vectorizer', vectorizer),('LR', clf)])\n",
    "y_pred = model.predict(X_test)\n",
    "print('Number of Features: %d'%len(vectorizer.get_feature_names()))\n",
    "print('Training Accuracy: %f'%metrics.accuracy_score(y_train, model.predict(recipes)))\n",
    "print('Testing Accuracy: %f'%metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features: 7000\n",
      "Training Accuracy: 0.863504\n",
      "Testing Accuracy: 0.833598\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=9)\n",
    "clf.fit(X_train, y_train)\n",
    "model = Pipeline([('vectorizer', vectorizer),('LR', clf)])\n",
    "y_pred = model.predict(X_test)\n",
    "print('Number of Features: %d'%len(vectorizer.get_feature_names()))\n",
    "print('Training Accuracy: %f'%metrics.accuracy_score(y_train, model.predict(recipes)))\n",
    "print('Testing Accuracy: %f'%metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import numpy as np\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "train_scores, valid_scores = validation_curve(LogisticRegression(), X_train, y_train, \"alpha\", train_sizes=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores, valid_scores = validation_curve(LogisticRegression(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features: 2268\n",
      "Training Accuracy: 0.842033\n",
      "Testing Accuracy: 0.781084\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=0.00003)\n",
    "vectorizer.fit(corpus)\n",
    "X_train = vectorizer.transform(recipes).toarray()\n",
    "y_train = labels\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "model = Pipeline([('vectorizer', vectorizer),('LR', clf)])\n",
    "y_pred = model.predict(X_test)\n",
    "print('Number of Features: %d'%len(vectorizer.get_feature_names()))\n",
    "print('Training Accuracy: %f'%metrics.accuracy_score(y_train, model.predict(recipes)))\n",
    "print('Testing Accuracy: %f'%metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features: 7000\n",
      "Training Accuracy: 0.869414\n",
      "Testing Accuracy: 0.827704\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,3),max_features=7000, stop_words=sw)\n",
    "vectorizer.fit(corpus)\n",
    "X_train = vectorizer.transform(recipes).toarray()\n",
    "y_train = labels\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "model = Pipeline([('vectorizer', vectorizer),('LR', clf)])\n",
    "y_pred = model.predict(X_test)\n",
    "print('Number of Features: %d'%len(vectorizer.get_feature_names()))\n",
    "print('Training Accuracy: %f'%metrics.accuracy_score(y_train, model.predict(recipes)))\n",
    "print('Testing Accuracy: %f'%metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features: 6794\n",
      "Training Accuracy: 0.870973\n",
      "Testing Accuracy: 0.795513\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,3), min_df=0.00003)\n",
    "vectorizer.fit(corpus)\n",
    "X_train = vectorizer.transform(recipes).toarray()\n",
    "y_train = labels\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "model = Pipeline([('vectorizer', vectorizer),('LR', clf)])\n",
    "y_pred = model.predict(X_test)\n",
    "print('Number of Features: %d'%len(vectorizer.get_feature_names()))\n",
    "print('Training Accuracy: %f'%metrics.accuracy_score(y_train, model.predict(recipes)))\n",
    "print('Testing Accuracy: %f'%metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features: 1734\n",
      "Training Accuracy: 0.833480\n",
      "Testing Accuracy: 0.814657\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=0.00003, stop_words=sw)\n",
    "vectorizer.fit(corpus)\n",
    "X_train = vectorizer.transform(recipes).toarray()\n",
    "y_train = labels\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "model = Pipeline([('vectorizer', vectorizer),('LR', clf)])\n",
    "y_pred = model.predict(X_test)\n",
    "print('Number of Features: %d'%len(vectorizer.get_feature_names()))\n",
    "print('Training Accuracy: %f'%metrics.accuracy_score(y_train, model.predict(recipes)))\n",
    "print('Testing Accuracy: %f'%metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features: 3689\n",
      "Training Accuracy: 0.856713\n",
      "Testing Accuracy: 0.823843\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2), min_df=0.00003, stop_words=sw)\n",
    "vectorizer.fit(corpus)\n",
    "X_train = vectorizer.transform(recipes).toarray()\n",
    "y_train = labels\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "model = Pipeline([('vectorizer', vectorizer),('LR', clf)])\n",
    "y_pred = model.predict(X_test)\n",
    "print('Number of Features: %d'%len(vectorizer.get_feature_names()))\n",
    "print('Training Accuracy: %f'%metrics.accuracy_score(y_train, model.predict(recipes)))\n",
    "print('Testing Accuracy: %f'%metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features: 9752\n",
      "Training Accuracy: 0.878048\n",
      "Testing Accuracy: 0.830468\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2), min_df=0.00001, stop_words=sw)\n",
    "vectorizer.fit(corpus)\n",
    "X_train = vectorizer.transform(recipes).toarray()\n",
    "y_train = labels\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "model = Pipeline([('vectorizer', vectorizer),('LR', clf)])\n",
    "y_pred = model.predict(X_test)\n",
    "print('Number of Features: %d'%len(vectorizer.get_feature_names()))\n",
    "print('Training Accuracy: %f'%metrics.accuracy_score(y_train, model.predict(recipes)))\n",
    "print('Testing Accuracy: %f'%metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features: 2683\n",
      "Training Accuracy: 0.849570\n",
      "Testing Accuracy: 0.819697\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2), min_df=0.00005, stop_words=sw)\n",
    "vectorizer.fit(corpus)\n",
    "X_train = vectorizer.transform(recipes).toarray()\n",
    "y_train = labels\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "model = Pipeline([('vectorizer', vectorizer),('LR', clf)])\n",
    "y_pred = model.predict(X_test)\n",
    "print('Number of Features: %d'%len(vectorizer.get_feature_names()))\n",
    "print('Training Accuracy: %f'%metrics.accuracy_score(y_train, model.predict(recipes)))\n",
    "print('Testing Accuracy: %f'%metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8420332090816672\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_train, model.predict(recipes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=0.00003, stop_words=sw, binary=True)\n",
    "vectorizer.fit(corpus)\n",
    "print('Number of Features: %d'%len(vectorizer.get_feature_names()))\n",
    "X_train = vectorizer.transform(recipes).toarray()\n",
    "y_train = labels\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "model = Pipeline([('vectorizer', vectorizer),('LR', clf)])\n",
    "y_pred = model.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vetorizer = CountVectorizer()\n",
    "vectorizer.fit(corpus)\n",
    "print('Number of Features: %d'%len(vectorizer.get_feature_names()))\n",
    "X_train = vectorizer.transform(recipes).toarray()\n",
    "y_train = labels\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "model = Pipeline([('vectorizer', vectorizer),('LR', clf)])\n",
    "y_pred = model.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features: 3689\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2), min_df=0.00003, stop_words=sw, binary=True)\n",
    "vectorizer.fit(corpus)\n",
    "print('Number of Features: %d'%len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.transform(recipes).toarray()\n",
    "y_train = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancheang/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/briancheang/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "LogReg_model = Pipeline([('vectorizer', vectorizer),('LR', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.85      0.48      0.61       117\n",
      "     british       0.60      0.30      0.40       201\n",
      "cajun_creole       0.81      0.65      0.72       387\n",
      "     chinese       0.86      0.92      0.89      3294\n",
      "    filipino       0.71      0.38      0.50       189\n",
      "      french       0.70      0.60      0.64      2205\n",
      "       greek       0.90      0.83      0.86      1544\n",
      "      indian       0.93      0.95      0.94      2119\n",
      "       irish       0.71      0.44      0.55       167\n",
      "     italian       0.76      0.99      0.86      4310\n",
      "    jamaican       0.82      0.57      0.67       132\n",
      "    japanese       0.88      0.80      0.84      1557\n",
      "      korean       0.77      0.59      0.67       208\n",
      "     mexican       0.90      0.97      0.93      3600\n",
      "    moroccan       0.83      0.64      0.72       206\n",
      "     russian       0.65      0.26      0.37       123\n",
      " southern_us       0.74      0.65      0.69      1080\n",
      "     spanish       0.85      0.69      0.76      1251\n",
      "        thai       0.84      0.75      0.80      1706\n",
      "  vietnamese       0.64      0.31      0.42       207\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     24603\n",
      "   macro avg       0.79      0.64      0.69     24603\n",
      "weighted avg       0.83      0.83      0.82     24603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_pred = LogReg_model.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model.sav'\n",
    "pickle.dump(LogReg_model, open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigramVec = CountVectorizer(min_df=0.00003, stop_words=sw, binary=True)\n",
    "unigramVec.fit(corpus)\n",
    "len(unigramVec.get_feature_names())\n",
    "X_train = unigramVec.transform(recipes).toarray()\n",
    "y_train = labels\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.81      0.41      0.55       117\n",
      "     british       0.55      0.25      0.35       201\n",
      "cajun_creole       0.77      0.63      0.69       387\n",
      "     chinese       0.84      0.91      0.87      3294\n",
      "    filipino       0.65      0.34      0.45       189\n",
      "      french       0.68      0.59      0.63      2205\n",
      "       greek       0.90      0.82      0.86      1544\n",
      "      indian       0.93      0.96      0.94      2119\n",
      "       irish       0.73      0.40      0.51       167\n",
      "     italian       0.76      0.98      0.86      4310\n",
      "    jamaican       0.82      0.58      0.68       132\n",
      "    japanese       0.88      0.80      0.84      1557\n",
      "      korean       0.74      0.53      0.62       208\n",
      "     mexican       0.89      0.96      0.93      3600\n",
      "    moroccan       0.83      0.61      0.70       206\n",
      "     russian       0.71      0.26      0.38       123\n",
      " southern_us       0.71      0.64      0.68      1080\n",
      "     spanish       0.86      0.68      0.76      1251\n",
      "        thai       0.82      0.72      0.77      1706\n",
      "  vietnamese       0.61      0.28      0.38       207\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     24603\n",
      "   macro avg       0.77      0.62      0.67     24603\n",
      "weighted avg       0.82      0.82      0.81     24603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "LogRegUni = Pipeline([('vectorizer', unigramVec),('LR', clf)])\n",
    "y_pred = LogRegUni.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.03      0.18      0.05       117\n",
      "     british       0.12      0.23      0.16       201\n",
      "cajun_creole       0.54      0.67      0.60       387\n",
      "     chinese       0.87      0.85      0.86      3294\n",
      "    filipino       0.33      0.28      0.30       189\n",
      "      french       0.41      0.32      0.36      2205\n",
      "       greek       0.85      0.74      0.79      1544\n",
      "      indian       0.93      0.89      0.91      2119\n",
      "       irish       0.13      0.32      0.19       167\n",
      "     italian       0.73      0.88      0.80      4310\n",
      "    jamaican       0.24      0.43      0.31       132\n",
      "    japanese       0.61      0.33      0.43      1557\n",
      "      korean       0.68      0.51      0.58       208\n",
      "     mexican       0.87      0.76      0.81      3600\n",
      "    moroccan       0.36      0.62      0.45       206\n",
      "     russian       0.10      0.16      0.12       123\n",
      " southern_us       0.57      0.56      0.57      1080\n",
      "     spanish       0.60      0.62      0.61      1251\n",
      "        thai       0.80      0.64      0.71      1706\n",
      "  vietnamese       0.32      0.40      0.36       207\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     24603\n",
      "   macro avg       0.50      0.52      0.50     24603\n",
      "weighted avg       0.72      0.69      0.70     24603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X_train, y_train)\n",
    "NB_model = Pipeline([('vectorizer', vectorizer),('LR', clf)])\n",
    "y_pred = NB_model.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.48      0.41      0.44       117\n",
      "     british       0.24      0.18      0.21       201\n",
      "cajun_creole       0.56      0.51      0.54       387\n",
      "     chinese       0.86      1.00      0.92      3294\n",
      "    filipino       0.50      0.32      0.39       189\n",
      "      french       0.60      0.57      0.59      2205\n",
      "       greek       0.78      0.78      0.78      1544\n",
      "      indian       0.86      0.88      0.87      2119\n",
      "       irish       0.33      0.25      0.28       167\n",
      "     italian       0.74      0.83      0.79      4310\n",
      "    jamaican       0.47      0.38      0.42       132\n",
      "    japanese       0.80      0.68      0.73      1557\n",
      "      korean       0.59      0.45      0.51       208\n",
      "     mexican       0.86      0.86      0.86      3600\n",
      "    moroccan       0.45      0.37      0.40       206\n",
      "     russian       0.20      0.15      0.17       123\n",
      " southern_us       0.56      0.50      0.53      1080\n",
      "     spanish       0.65      0.62      0.63      1251\n",
      "        thai       0.75      0.65      0.70      1706\n",
      "  vietnamese       0.33      0.28      0.30       207\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     24603\n",
      "   macro avg       0.58      0.53      0.55     24603\n",
      "weighted avg       0.74      0.75      0.74     24603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "DT_model = Pipeline([('vectorizer', vectorizer),('LR', clf)])\n",
    "y_pred = DT_model.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brazilian top ingredients:\n",
      "cachaca\n",
      "granola\n",
      "brown basmati\n",
      "crema\n",
      "starch\n",
      "instant coffee\n",
      "palm\n",
      "cookies\n",
      "tapioca flour\n",
      "idaho\n",
      "============================\n",
      "british top ingredients:\n",
      "scotch\n",
      "crumbles\n",
      "haddock\n",
      "chili flake\n",
      "gingerroot\n",
      "pound\n",
      "baked\n",
      "style plain\n",
      "port\n",
      "chicken stock\n",
      "============================\n",
      "cajun_creole top ingredients:\n",
      "creole\n",
      "cajun\n",
      "andouille\n",
      "crawfish\n",
      "salami\n",
      "smoked sausage\n",
      "chicken sausage\n",
      "fat mayonnaise\n",
      "okra\n",
      "pecan\n",
      "============================\n",
      "chinese top ingredients:\n",
      "mandarin\n",
      "szechwan\n",
      "chinese\n",
      "mein\n",
      "char\n",
      "conimex\n",
      "custard\n",
      "spring onion\n",
      "yardlong\n",
      "chili oil\n",
      "============================\n",
      "filipino top ingredients:\n",
      "coriander seed\n",
      "green mango\n",
      "tilapia\n",
      "jackfruit\n",
      "oregano leaf\n",
      "blackberry\n",
      "serrano chile\n",
      "mung\n",
      "chili paste\n",
      "peppercorn\n",
      "============================\n",
      "french top ingredients:\n",
      "fried\n",
      "herbes\n",
      "vanilla cake\n",
      "onion soup\n",
      "challa\n",
      "calvados\n",
      "delicious\n",
      "creamer\n",
      "blanc\n",
      "cognac\n",
      "============================\n",
      "greek top ingredients:\n",
      "greek\n",
      "phyllo\n",
      "yogurt\n",
      "greek seasoning\n",
      "lamb\n",
      "yoghurt\n",
      "tahini\n",
      "feta\n",
      "oregano\n",
      "feta cheese\n",
      "============================\n",
      "indian top ingredients:\n",
      "tandoori\n",
      "masala\n",
      "naan\n",
      "cardamom\n",
      "curry\n",
      "urad\n",
      "chutney\n",
      "yoghurt\n",
      "cardamon\n",
      "yellow cornmeal\n",
      "============================\n",
      "irish top ingredients:\n",
      "irish\n",
      "color\n",
      "stout\n",
      "coconut cream\n",
      "sweet cherry\n",
      "sweet sausage\n",
      "rhubarb\n",
      "beer\n",
      "potato\n",
      "lowfat\n",
      "============================\n",
      "italian top ingredients:\n",
      "mascarpone\n",
      "polenta\n",
      "risotto\n",
      "gnocchi\n",
      "fettucine\n",
      "sausage\n",
      "amaretto\n",
      "arborio\n",
      "linguine\n",
      "salad dressing\n",
      "============================\n",
      "jamaican top ingredients:\n",
      "season\n",
      "pigeon\n",
      "allspice\n",
      "thyme\n",
      "rum\n",
      "cheese chicken\n",
      "habanero\n",
      "spice\n",
      "plantain\n",
      "chicken pepper\n",
      "============================\n",
      "japanese top ingredients:\n",
      "panko\n",
      "sake\n",
      "mirin\n",
      "bonito\n",
      "miso\n",
      "udon\n",
      "soba\n",
      "wasabi\n",
      "dashi\n",
      "konbu\n",
      "============================\n",
      "korean top ingredients:\n",
      "kimchi\n",
      "gochujang\n",
      "korean\n",
      "thyme leaf\n",
      "pear\n",
      "pepper egg\n",
      "virgin coconut\n",
      "white flour\n",
      "cream chicken\n",
      "chinese cabbage\n",
      "============================\n",
      "mexican top ingredients:\n",
      "tequila\n",
      "mexican\n",
      "masa\n",
      "piloncillo\n",
      "jicama\n",
      "tortilla\n",
      "queso\n",
      "taco\n",
      "salsa\n",
      "tortillas\n",
      "============================\n",
      "moroccan top ingredients:\n",
      "harissa\n",
      "couscous\n",
      "flower\n",
      "anise seed\n",
      "navy\n",
      "green tea\n",
      "garlic oil\n",
      "semolina\n",
      "scallop\n",
      "chicken soup\n",
      "============================\n",
      "russian top ingredients:\n",
      "light mayonnaise\n",
      "beet\n",
      "vegeta\n",
      "sour\n",
      "dill\n",
      "garlic chili\n",
      "poppy\n",
      "pork chop\n",
      "spelt\n",
      "buckwheat\n",
      "============================\n",
      "southern_us top ingredients:\n",
      "collard\n",
      "quickcooking\n",
      "lima\n",
      "grit\n",
      "green tomato\n",
      "biscuit\n",
      "buttermilk\n",
      "whiskey\n",
      "country ham\n",
      "poultry\n",
      "============================\n",
      "spanish top ingredients:\n",
      "spanish\n",
      "pimenton\n",
      "chorizo\n",
      "piquillo\n",
      "saffron\n",
      "sherry\n",
      "capsicum\n",
      "triple\n",
      "manchego cheese\n",
      "manchego\n",
      "============================\n",
      "thai top ingredients:\n",
      "teas\n",
      "thai\n",
      "sweet chili\n",
      "palm sugar\n",
      "mixed salad\n",
      "almond butter\n",
      "tea\n",
      "sunflower seed\n",
      "peanut\n",
      "curry paste\n",
      "============================\n",
      "vietnamese top ingredients:\n",
      "vietnamese\n",
      "tapioca\n",
      "chicken fillet\n",
      "unsalted chicken\n",
      "coffee\n",
      "idaho\n",
      "diced chicken\n",
      "diced yellow\n",
      "catfish\n",
      "mung\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in range(0, clf.coef_.shape[0]):\n",
    "    print('%s top ingredients:' % clf.classes_[i])\n",
    "    top5_indices = np.argsort(clf.coef_[i])[-10:]\n",
    "    for j in top5_indices[::-1]:  \n",
    "        print features[j]\n",
    "    print('============================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_recipe = raw_input(\"Input Recipe: \\n> \")\n",
    "input_recipe = stem(input_recipe.lower())\n",
    "X_input = vectorizer.transform([input_recipe]).toarray()\n",
    "prob = clf.predict_proba(X_input)[0]\n",
    "classes = clf.classes_\n",
    "T\n",
    "print('\\nIdentified Ingredients: \\n> %s'%vectorizer.inverse_transform(X_input))\n",
    "\n",
    "print('\\nCuisine Probabilities:')\n",
    "for i in range(len(prob)):\n",
    "    print('> %s: %s%%'%(classes[i], int(prob[i]*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'LogReg_v5.sav'\n",
    "pickle.dump(LogReg_model, open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
